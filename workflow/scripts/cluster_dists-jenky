#!/usr/bin/env python

import scipy
import sys
import matplotlib.ticker as ticker
import pandas as pd
import numpy as np
import re
import glob
import os
import argparse
from loguru import logger
from sklearn.cluster import DBSCAN, OPTICS
import jenkspy
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.collections import PathCollection
import concurrent.futures


def read_and_filter_csv(file):
    df = pd.read_csv(file)
    # Filter out columns that are entirely NA
    filtered_df = df.dropna(axis=1, how='all')
    return filtered_df


# Function to calculate SSD for given breaks
def calculate_ssd(data, breaks):
    ssd = 0
    for i in range(len(breaks) - 1):
        class_data = [x for x in data if breaks[i] <= x < breaks[i + 1]]
        class_mean = np.mean(class_data)
        ssd += sum((x - class_mean)**2 for x in class_data)
    return ssd


# Function to find the optimal number of breaks using the elbow method
def find_optimal_breaks(data, max_clusters, output):
    ssd_values = []
    for k in range(1, max_clusters + 1):
        breaks = jenkspy.jenks_breaks(data, nb_class=k)
        ssd = calculate_ssd(data, breaks)
        ssd_values.append(ssd)

    # Plot SSD values to find the elbow
    plt.plot(range(1, max_clusters + 1), ssd_values, marker='o')
    plt.xlabel('Number of Classes')
    plt.ylabel('Sum of Squared Deviations (SSD)')
    plt.title('Elbow Method for Optimal Number of Classes')
    sns.despine()
    sns.despine(left=True, ax=axs[1])

    # Adjust layout to not overlap and save the figure
    plt.tight_layout()

    plt.savefig(output, dpi=300, transparent=True)
    plt.show()

    # Find the elbow point
    diff = np.diff(ssd_values)
    optimal_k = np.argmin(
        diff) + 1  # +1 because diff reduces the array size by 1
    return optimal_k


# Function to read all CSV files and concatenate them into a single DataFrame
def aggregate_results(folder_path):
    all_files = glob.glob(folder_path + "/*.csv")
    df = pd.DataFrame()
    for f in all_files:
        indiv_data = read_and_filter_csv(f)
        basename_f = os.path.basename(f)
        bucket_f = re.sub(r"(_\d+)-filterdists\.csv", "", basename_f)
        indiv_data['Bucket'] = bucket_f
        df = pd.concat((df, indiv_data), ignore_index=True)
    return df


def assign_cluster_colors(labels):
    # Sort unique labels, ensuring -1 is last
    unique_labels = sorted(set(labels), key=lambda x: (x == -1, x))
    logger.debug(f"Sorted Labels: {unique_labels}")

    # Get colors from the seaborn muted palette
    n_colors = len(unique_labels)
    logger.debug(f"Number of colors: {n_colors}")

    # Generate a color palette with enough distinct colors
    base_palette = sns.color_palette("muted", as_cmap=False).as_hex()
    if n_colors > len(base_palette):
        logger.warning(
            f"{n_colors} is more than in the seaborn palette. Adding new colors with different brightness."
        )
        extended_palette = base_palette + sns.color_palette(
            "muted", n_colors - len(base_palette), desat=0.6).as_hex()
    else:
        extended_palette = base_palette

    colors = extended_palette[:n_colors]
    logger.debug(f"Available colors: {colors}")

    # Initialize label_color_map with regular clusters
    label_color_map = {
        label: colors[i]
        for i, label in enumerate(unique_labels) if label != -1
    }

    # If -1 is in labels, assign it the last color from the palette
    if -1 in unique_labels:
        label_color_map[-1] = colors[
            -1]  # Assigning the last color in the palette to -1

    return label_color_map


# Function to process a single gene
def process_gene(gene, gene_data, epsilon, min_samples, output_dir):
    logger.debug(f"Processing gene: {gene}")
    gene_name = gene
    if '/' in gene_name:
        logger.warning(f"{gene_name} contains '/', replacing '/' with ':'")
        gene_name = gene_name.replace('/', ':')
        logger.warning(f"{gene_name} replaces {gene}")
    if '|' in gene_name:
        logger.warning(f"{gene_name} contains '|', replacing '|' with ':'")
        gene_name = gene_name.replace('|', ':')
        logger.warning(f"{gene_name} replaces {gene}")
    if '(' in gene_name:
        logger.warning(f"{gene_name} contains '(', replacing with ':'")
        gene_name = gene_name.replace('(', ':')
        logger.warning(f"{gene_name} replaces {gene}")
    if ')' in gene_name:
        logger.warning(f"{gene_name} contains ')', replacing with ':'")
        gene_name = gene_name.replace(')', ':')
        logger.warning(f"{gene_name} replaces {gene}")
    if "'" in gene_name:
        logger.warning(f"{gene_name} contains \"'\", replacting with ':'")
        gene_name = gene_name.replace("'", ":")

    differences = gene_data['Difference'].values.reshape(-1, 1)
    create_plot(
        gene_data, gene_name,
        os.path.join(output_dir, "all_gene_dists",
                     f"{gene_name}_distances.png"))
    logger.debug(f"Clustering differences")
    optics = OPTICS(max_eps=epsilon,
                    min_samples=min_samples,
                    n_jobs=-1,
                    metric='manhattan')
    logger.debug(f"Fitting labels")
    labels = optics.fit_predict(differences)
    logger.debug(f"Removing outliers")
    filtered_data = gene_data[labels != -1]['Difference'].values

    # Find the optimal number of breaks using the elbow method
    optimal_k = find_optimal_breaks(
        filtered_data, max_clusters,
        os.path.join(output_dir, "all_gene_dists",
                     f"{gene_name}_elbowplot.png"))

    # Apply Jenks Natural Breaks with the optimal number of classes
    breaks = jenkspy.jenks_breaks(filtered_data, nb_class=optimal_k)

    # Assign clusters based on breaks
    cluster_labels = np.digitize(gene_data['Difference'],
                                 bins=breaks,
                                 right=True)
    gene_data['Cluster'] = cluster_labels

    logger.debug(f"Checking gene labels")

    # Check if the gene meets the criteria
    label_set = set(labels)
    if (-1 in label_set and len(label_set) <= 2) or len(label_set) < 2:
        return gene, None, False, None

    logger.info(
        f"{gene} passed filter with the following clusters: {label_set}")

    # Compute mean distance for each cluster except noise (-1)
    cluster_means = {}
    for label in label_set:
        if label != -1:
            cluster_members = differences[labels == label]
            mean_distance = np.mean(cluster_members)
            cluster_means[label] = mean_distance

    # Sort clusters based on their mean distance and assign new labels
    sorted_clusters = sorted(cluster_means, key=cluster_means.get)
    cluster_mapping = {
        old_label: new_label
        for new_label, old_label in enumerate(sorted_clusters)
    }

    # Replace old labels with new labels
    new_labels = np.array(
        [cluster_mapping[label] if label != -1 else -1 for label in labels])

    # Create a mapping from unique values to labels
    # mapping = dict(zip(gene_data_unique["Difference"], new_labels))
    mapping = dict(zip(gene_data['Difference'], new_labels))

    gene_df = gene_data.copy()
    gene_df["Cluster"] = gene_df['Difference'].map(mapping)
    outdir = os.path.join(output_dir, "passing_genes", gene_name)
    os.makedirs(outdir, exist_ok=True)

    # Plotting and saving
    create_plot(gene_df, gene_name,
                os.path.join(outdir, f"{gene_name}_clusters.png"))
    # create_violin_plot_ofclusters(
    # gene_df, gene_name, os.path.join(outdir,
    # f"{gene_name}_coloreddist.png"))
    # create_kde_plot(gene_df, gene_name,
    # os.path.join(outdir, f"{gene_name}_kde.png"))
    gene_df.to_csv(os.path.join(outdir, f"{gene_name}_clusters.csv"),
                   index=False)

    return gene, mapping, True, gene_name


# Function to perform clustering and save results
def cluster_gene_differences_threaded(df, epsilon, min_samples, output_dir):
    if len(df) == 0:
        return 0, 0

    grouped_data = df.groupby('GeneID')

    num_failing_genes = 0
    num_passing_genes = 0
    with concurrent.futures.ProcessPoolExecutor() as executor:
        futures = {}
        for gene, gene_data in grouped_data:
            futures[executor.submit(process_gene, gene, gene_data, epsilon,
                                    min_samples, output_dir)] = gene

        for future in concurrent.futures.as_completed(futures):
            gene, mapping, is_worthy, gene_name = future.result()

            if is_worthy:
                num_passing_genes += 1
            else:
                num_failing_genes += 1
    return num_passing_genes, num_failing_genes


def create_plot(big_df, gene_id, output):
    if 'Cluster' in big_df.columns:
        big_df['Cluster'] = big_df['Cluster'].astype(str)
        palette_ints = assign_cluster_colors(big_df['Cluster'].astype(int))
        palette = {}
        for i in palette_ints:
            palette[str(i)] = palette_ints[i]
    # Create a figure with two subplots (rows), sharing the same x-axis
    fig, axs = plt.subplots(2,
                            1,
                            figsize=(5, 4),
                            sharex=True,
                            gridspec_kw={'height_ratios': [3, 1]})

    # First plot (KDE) on the first subplot
    sns.histplot(data=big_df,
                 x="Difference",
                 ax=axs[0],
                 fill=False,
                 color='black')
    axs[0].set_ylabel("Number of Genomes")
    axs[0].set_title(f"{gene_id}")
    # Remove x-axis label for the top plot to only have it at the bottom plot
    axs[0].set_xlabel("")
    axs[0].yaxis.set_major_formatter(
        ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)
                             if x == 0 else '{:,.3g}'.format(x / 1000) + 'K'))

    if 'Cluster' in big_df.columns:
        # Second plot (Stripplot and Violinplot) on the second subplot
        sns.stripplot(x='Difference',
                      data=big_df.sort_values(
                          'Cluster', key=lambda x: x.replace('-1', 'A')),
                      hue='Cluster',
                      orient="h",
                      ax=axs[1],
                      alpha=0.8,
                      palette=palette)
    else:
        sns.stripplot(
            x='Difference',
            data=big_df,
            color='black',
            orient="h",
            ax=axs[1],
            alpha=0.8,
        )

    sns.violinplot(x='Difference',
                   data=big_df,
                   fill=True,
                   inner=None,
                   cut=0,
                   color='lightgrey',
                   alpha=0.8,
                   split=False,
                   ax=axs[1])

    if "Cluster" in big_df.columns:
        handles, labels = axs[1].get_legend_handles_labels()
        fig.legend(handles,
                   labels,
                   title="Cluster",
                   bbox_transform=fig.transFigure)
        axs[1].get_legend().remove()

    # Set labels for the second plot
    axs[1].set_xlabel("Prefix-suffix distance relative to gene length")
    axs[1].xaxis.set_major_formatter(
        ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)
                             if x == 0 else '{:,.3g}'.format(x / 1000) + 'kb'))
    axs[1].set(ylabel=None)  # Remove y-axis label
    axs[1].set_yticks([])
    sns.despine()
    sns.despine(left=True, ax=axs[1])

    # Adjust layout to not overlap and save the figure
    plt.tight_layout()

    plt.savefig(output, dpi=300, transparent=True)
    plt.close()


def main():
    parser = argparse.ArgumentParser(description="Gene clustering script.")
    parser.add_argument(
        "-i",
        "--input_dir",
        type=str,
        required=True,
        help="Directory containing input CSV files.",
    )
    parser.add_argument(
        "-o",
        "--output_dir",
        type=str,
        required=True,
        help="Directory to store output files.",
    )
    parser.add_argument("--epsilon",
                        type=float,
                        default=800,
                        help="Epsilon value for DBSCAN.")
    parser.add_argument("--min_samples",
                        type=int,
                        default=20,
                        help="Minimum samples value for DBSCAN.")
    parser.add_argument(
        "-v",
        "--verbose",
        action="count",
        default=0,
        help=
        "Increase verbosity level. Can be specified multiple times for more detailed logs.",
    )

    args = parser.parse_args()

    if args.verbose == 0:
        logger.remove()
    elif args.verbose == 1:
        logger.remove()
        logger.add(sys.stderr, level="INFO")
    elif args.verbose >= 2:
        logger.remove()
        logger.add(sys.stderr, level="DEBUG")

    os.makedirs(os.path.join(args.output_dir, "all_gene_dists"), exist_ok=True)
    passinggenesdir = os.path.join(args.output_dir, "passing_genes")
    os.makedirs(passinggenesdir, exist_ok=True)
    logger.debug("Aggregating inputs")
    df = aggregate_results(args.input_dir)
    # print(df)
    logger.info("Read all input files.")
    (num_passing_genes, num_failing_genes) = cluster_gene_differences_threaded(
        df, args.epsilon, args.min_samples, args.output_dir)
    if num_passing_genes + num_failing_genes == 0:
        logger.info("No genes passed filters.")
    else:
        logger.info(
            f"Passing genes: {num_passing_genes} ({(num_passing_genes/(num_passing_genes+num_failing_genes))*100}%)\nFailing genes: {num_failing_genes} ({(num_failing_genes/(num_passing_genes+num_failing_genes))*100}%)"
        )
    logger.success("Complete.")


if __name__ == "__main__":
    main()
