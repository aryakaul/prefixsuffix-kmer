#!/usr/bin/env python

import dask.bag as db
import scipy
import sys
import matplotlib.ticker as ticker
import pandas as pd
import numpy as np
import re
import glob
import os
import argparse
import dask.dataframe as dd
from loguru import logger
from sklearn.cluster import DBSCAN, OPTICS
from dbscan1d.core import DBSCAN1D
import seaborn as sns
import matplotlib.pyplot as plt
import dask.dataframe as dd
from dask import delayed, compute
from dask.distributed import Client
from matplotlib.collections import PathCollection
from multiprocessing import Pool
import concurrent.futures


def aggregate_results_dask(folder_path):
    csv_pattern = os.path.join(folder_path, "*.csv.gz")

    # Read all CSV files into a Dask DataFrame
    df = dd.read_csv(csv_pattern,
                     assume_missing=True,
                     usecols=[
                         "GeneID", "Difference", "GenomeID", "Contig",
                         "PrefixLocation", "SuffixLocation"
                     ],
                     include_path_column=True,
                     compression='gzip',
                     blocksize=None)
    df['Bucket'] = df['path'].str.extract(
        r"([^/]+)(?:_\d+-filterdists\.csv.gz)$", expand=False)

    return df


def assign_cluster_colors(labels):
    # Sort unique labels, ensuring -1 is last
    unique_labels = sorted(set(labels), key=lambda x: (x == -1, x))
    logger.debug(f"Sorted Labels: {unique_labels}")

    # Get colors from the seaborn muted palette
    n_colors = len(unique_labels)
    logger.debug(f"Number of colors: {n_colors}")

    # Generate a color palette with enough distinct colors
    base_palette = sns.color_palette("muted", as_cmap=False).as_hex()
    if n_colors > len(base_palette):
        logger.warning(
            f"{n_colors} is more than in the seaborn palette. Adding new colors with different brightness."
        )
        extended_palette = (base_palette + sns.color_palette(
            "muted", n_colors - len(base_palette), desat=0.6).as_hex())
    else:
        extended_palette = base_palette

    colors = extended_palette[:n_colors]
    logger.debug(f"Available colors: {colors}")

    # Initialize label_color_map with regular clusters
    label_color_map = {
        label: colors[i]
        for i, label in enumerate(unique_labels) if label != -1
    }

    # If -1 is in labels, assign it the last color from the palette
    if -1 in unique_labels:
        label_color_map[-1] = colors[
            -1]  # Assigning the last color in the palette to -1

    return label_color_map


def cluster_gene_differences_dask(df, epsilon, min_samples, output_dir,
                                  remove_outliers, client):
    # Compute unique GeneIDs
    gene_ids = df["GeneID"].drop_duplicates().compute()

    # List to hold futures
    futures = []

    for gene in gene_ids:
        # Select data for the gene (still a Dask DataFrame)
        gene_data_ddf = df[df["GeneID"] == gene]
        # Submit the task to the client without computing the data
        future = client.submit(
            process_gene,
            gene,
            gene_data_ddf,
            epsilon,
            min_samples,
            output_dir,
            remove_outliers,
        )
        futures.append(future)

    # Gather results
    results = client.gather(futures)

    num_passing_genes = sum(1 for res in results if res[2])
    num_failing_genes = sum(1 for res in results if not res[2])

    return num_passing_genes, num_failing_genes


def process_gene(gene,
                 gene_data_ddf,
                 epsilon,
                 min_samples,
                 output_dir,
                 remove_outliers=False):
    # Compute the gene data into memory as a Pandas DataFrame
    gene_data = gene_data_ddf.compute()

    logger.debug(f"Processing gene: {gene}")
    gene_name = gene.replace("/", ":").replace("|",
                                               ":").replace("(", ":").replace(
                                                   ")", ":").replace("'", ":")

    # Count the occurrences of each unique value for sample_weight
    value_counts = gene_data['Difference'].value_counts()

    # Remove exact duplicates
    gene_data_unique = gene_data.drop_duplicates(subset=["Difference"])

    # Reshape for DBSCAN
    differences = gene_data_unique["Difference"].values.reshape(-1, 1)

    logger.debug(f"Clustering differences")
    dbscan = DBSCAN1D(eps=epsilon, min_samples=min_samples)
    logger.debug(f"Fitting labels")

    # Use sample_weight in DBSCAN
    sample_weight = value_counts.loc[gene_data_unique["Difference"]].values
    labels = dbscan.fit_predict(differences, sample_weight=sample_weight)

    logger.debug(f"Checking gene labels")
    # Check if the gene meets the criteria
    label_set = set(labels)
    if (-1 in label_set and len(label_set) <= 2) or len(label_set) < 2:
        return gene, None, False, None

    logger.info(
        f"{gene} passed filter with the following clusters: {label_set}")

    # Compute mean distance for each cluster except noise (-1)
    cluster_means = {}
    for label in label_set:
        if label != -1:
            cluster_members = differences[labels == label]
            mean_distance = np.mean(cluster_members)
            cluster_means[label] = mean_distance

    # Sort clusters based on their mean distance and assign new labels
    sorted_clusters = sorted(cluster_means, key=cluster_means.get)
    cluster_mapping = {
        old_label: new_label
        for new_label, old_label in enumerate(sorted_clusters)
    }

    # Replace old labels with new labels
    new_labels = np.array(
        [cluster_mapping[label] if label != -1 else -1 for label in labels])

    # Create a mapping from unique values to labels
    mapping = dict(zip(gene_data_unique["Difference"], new_labels))

    # Add 'Cluster' column to gene_data
    gene_data["Cluster"] = gene_data["Difference"].map(mapping)

    outdir = os.path.join(output_dir, "passing_genes", gene_name)
    os.makedirs(outdir, exist_ok=True)

    # Plotting and saving
    if remove_outliers:
        plot_data = gene_data.loc[gene_data["Cluster"] != -1]
    else:
        plot_data = gene_data

    create_plot(
        plot_data,
        gene_name,
        os.path.join(outdir, f"{gene_name}_clusters.png"),
    )

    # Save the DataFrame to CSV
    gene_data.to_csv(os.path.join(outdir, f"{gene_name}_clusters.csv.gz"),
                     index=False)

    return gene, mapping, True, gene_name


#def process_gene(gene,
#                 gene_data_ddf,
#                 epsilon,
#                 min_samples,
#                 output_dir,
#                 remove_outliers=False):
#
#    # Compute the gene data on the worker
#    # gene_data = gene_data_ddf.compute()
#    # gene_data_ddf = gene_data_ddf.persist()
#
#    logger.debug(f"Processing gene: {gene}")
#    gene_name = gene
#    if "/" in gene_name:
#        logger.warning(f"{gene_name} contains '/', replacing '/' with ':'")
#        gene_name = gene_name.replace("/", ":")
#        logger.warning(f"{gene_name} replaces {gene}")
#    if "|" in gene_name:
#        logger.warning(f"{gene_name} contains '|', replacing '|' with ':'")
#        gene_name = gene_name.replace("|", ":")
#        logger.warning(f"{gene_name} replaces {gene}")
#    if "(" in gene_name:
#        logger.warning(f"{gene_name} contains '(', replacing with ':'")
#        gene_name = gene_name.replace("(", ":")
#        logger.warning(f"{gene_name} replaces {gene}")
#    if ")" in gene_name:
#        logger.warning(f"{gene_name} contains ')', replacing with ':'")
#        gene_name = gene_name.replace(")", ":")
#        logger.warning(f"{gene_name} replaces {gene}")
#    if "'" in gene_name:
#        logger.warning(f"{gene_name} contains \"'\", replacting with ':'")
#        gene_name = gene_name.replace("'", ":")
#
#    # Count the occurrences of each unique value for sample_weight
#    # value_counts = gene_data["Difference"].value_counts()
#    value_counts = gene_data_ddf['Difference'].value_counts().compute()
#
#    # Remove exact duplicates
#    # gene_data_unique = gene_data.drop_duplicates(subset=["Difference"])
#    gene_data_unique_ddf = gene_data_ddf.drop_duplicates(subset=["Difference"])
#    gene_data_unique = gene_data_unique_ddf.compute()
#
#    # Reshape for DBSCAN
#    differences = gene_data_unique["Difference"].values.reshape(-1, 1)
#
#
#    # create_plot(
#    # gene_data,
#    # gene_name,
#    # os.path.join(output_dir, "all_gene_dists", f"{gene_name}_distances.png"),
#    # )
#
#    logger.debug(f"Clustering differences")
#    dbscan = DBSCAN1D(eps=epsilon, min_samples=min_samples)
#    logger.debug(f"Fitting labels")
#
#    # Use sample_weight in DBSCAN
#    sample_weight = value_counts.loc[gene_data_unique["Difference"]].values
#    labels = dbscan.fit_predict(differences, sample_weight=sample_weight)
#
#    logger.debug(f"Checking gene labels")
#    # Check if the gene meets the criteria
#    label_set = set(labels)
#    if (-1 in label_set and len(label_set) <= 2) or len(label_set) < 2:
#        return gene, None, False, None
#
#    logger.info(
#        f"{gene} passed filter with the following clusters: {label_set}")
#
#    # Compute mean distance for each cluster except noise (-1)
#    cluster_means = {}
#    for label in label_set:
#        if label != -1:
#            cluster_members = differences[labels == label]
#            mean_distance = np.mean(cluster_members)
#            cluster_means[label] = mean_distance
#
#    # Sort clusters based on their mean distance and assign new labels
#    sorted_clusters = sorted(cluster_means, key=cluster_means.get)
#    cluster_mapping = {
#        old_label: new_label
#        for new_label, old_label in enumerate(sorted_clusters)
#    }
#
#    # Replace old labels with new labels
#    new_labels = np.array(
#        [cluster_mapping[label] if label != -1 else -1 for label in labels])
#
#    # Create a mapping from unique values to labels
#    mapping = dict(zip(gene_data_unique["Difference"], new_labels))
#
#    # gene_df = gene_data.copy()
#    gene_data_ddf["Cluster"] = gene_data_ddf["Difference"].map(mapping)
#    outdir = os.path.join(output_dir, "passing_genes", gene_name)
#    os.makedirs(outdir, exist_ok=True)
#
#    # Plotting and saving
#    if remove_outliers:
#        create_plot(
#            gene_data_ddf.loc[gene_data_ddf["Cluster"] != -1].compute(),
#            gene_name,
#            os.path.join(outdir, f"{gene_name}_clusters.png"),
#        )
#    # else:
#    # create_plot(
#    # gene_df, gene_name, os.path.join(outdir, f"{gene_name}_clusters.png")
#    # )
#    gene_data_ddf.to_csv(os.path.join(outdir, f"{gene_name}_clusters.csv"),
#                   index=False)
#
#    return gene, mapping, True, gene_name


def create_plot(big_df, gene_id, output):
    big_df = big_df.copy()
    if "Cluster" in big_df.columns:
        palette_ints = assign_cluster_colors(big_df["Cluster"].astype(int))
        big_df["Cluster"] = big_df["Cluster"].astype(str)
        palette = {}
        for i in palette_ints:
            palette[str(i)] = palette_ints[i]

    # Create a figure with two subplots (rows), sharing the same x-axis
    fig, axs = plt.subplots(2,
                            1,
                            figsize=(5, 4),
                            sharex=True,
                            gridspec_kw={"height_ratios": [3, 1]})

    # First plot (KDE) on the first subplot
    sns.histplot(data=big_df,
                 x="Difference",
                 ax=axs[0],
                 fill=False,
                 color="black")
    axs[0].set_ylabel("Number of Genomes")
    axs[0].set_title(f"{gene_id}")
    # Remove x-axis label for the top plot to only have it at the bottom plot
    axs[0].set_xlabel("")
    axs[0].yaxis.set_major_formatter(
        ticker.FuncFormatter(lambda x, pos: "{:,.0f}".format(x)
                             if x == 0 else "{:,.3g}".format(x / 1000) + "K"))

    if "Cluster" in big_df.columns:
        # Second plot (Stripplot and Violinplot) on the second subplot
        sns.stripplot(
            x="Difference",
            data=big_df.sort_values("Cluster",
                                    key=lambda x: x.replace("-1", "A")),
            hue="Cluster",
            orient="h",
            ax=axs[1],
            alpha=0.8,
            palette=palette,
        )
    else:
        sns.stripplot(
            x="Difference",
            data=big_df,
            color="black",
            orient="h",
            ax=axs[1],
            alpha=0.8,
        )

    sns.violinplot(
        x="Difference",
        data=big_df,
        fill=True,
        inner=None,
        cut=0,
        color="lightgrey",
        alpha=0.8,
        split=False,
        ax=axs[1],
    )

    if "Cluster" in big_df.columns:
        handles, labels = axs[1].get_legend_handles_labels()
        fig.legend(handles,
                   labels,
                   title="Cluster",
                   bbox_transform=fig.transFigure)
        axs[1].get_legend().remove()

    # Set labels for the second plot
    axs[1].set_xlabel("Prefix-suffix distance relative to gene length")
    axs[1].xaxis.set_major_formatter(
        ticker.FuncFormatter(lambda x, pos: "{:,.0f}".format(x)
                             if x == 0 else "{:,.3g}".format(x / 1000) + "kb"))
    axs[1].set(ylabel=None)  # Remove y-axis label
    axs[1].set_yticks([])
    sns.despine()
    sns.despine(left=True, ax=axs[1])

    # Adjust layout to not overlap and save the figure
    plt.tight_layout()

    plt.savefig(output, dpi=300, transparent=True)
    plt.close()


def main():
    parser = argparse.ArgumentParser(description="Gene clustering script.")
    parser.add_argument(
        "-i",
        "--input_dir",
        type=str,
        required=True,
        help="Directory containing input CSV files.",
    )
    parser.add_argument(
        "-o",
        "--output_dir",
        type=str,
        required=True,
        help="Directory to store output files.",
    )
    parser.add_argument("--epsilon",
                        type=float,
                        default=800,
                        help="Epsilon value for OPTICS.")
    parser.add_argument("--min_samples",
                        type=int,
                        default=75,
                        help="Minimum samples value for OPTICS.")
    parser.add_argument(
        "--remove_outliers",
        action="store_true",
        help="Whether to remove or keep outliers in plots.",
    )
    parser.add_argument(
        "-v",
        "--verbose",
        action="count",
        default=0,
        help=
        "Increase verbosity level. Can be specified multiple times for more detailed logs.",
    )

    args = parser.parse_args()

    if args.verbose == 0:
        logger.remove()
    elif args.verbose == 1:
        logger.remove()
        logger.add(sys.stderr, level="INFO")
    elif args.verbose >= 2:
        logger.remove()
        logger.add(sys.stderr, level="DEBUG")

    client = Client()
    logger.debug(f"Dask client started: {client}")

    os.makedirs(os.path.join(args.output_dir, "all_gene_dists"), exist_ok=True)
    passinggenesdir = os.path.join(args.output_dir, "passing_genes")
    os.makedirs(passinggenesdir, exist_ok=True)

    logger.debug("Aggregating inputs")
    df = aggregate_results_dask(args.input_dir)
    logger.info("Read all input files.")

    (num_passing_genes, num_failing_genes) = cluster_gene_differences_dask(
        df,
        args.epsilon,
        args.min_samples,
        args.output_dir,
        args.remove_outliers,
        client,
    )
    if num_passing_genes + num_failing_genes == 0:
        logger.info("No genes passed filters.")
    else:
        logger.info(
            f"Passing genes: {num_passing_genes} ({(num_passing_genes/(num_passing_genes+num_failing_genes))*100}%)\nFailing genes: {num_failing_genes} ({(num_failing_genes/(num_passing_genes+num_failing_genes))*100}%)"
        )
    logger.success("Complete.")

    client.close()


if __name__ == "__main__":
    main()
